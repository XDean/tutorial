import Image from 'next/image'
import sparkStack from '../../../../../public/spark/resources/spark-stack.png'
import sparkDownload from '../../../../../public/spark/resources/spark-download.png'

export const meta = {
  id: 'overview',
  name: '准备',
}

## 关于本教程

- 本教程基于Spark v3.1.2, Python 3.6
- 主要参考[Spark官方文档](https://spark.apache.org/docs/3.1.2/)
- 示例代码主要使用Python，未来可能会添加Scala示例
- 内容不包含集群的安装部署

## 关于Spark

- Spark是用于处理大规模数据的计算引擎
- Spark主要提供了Java，Scala，Python和R语言的高级API
- Spark为结构化数据处理提供了[Spark SQL](https://spark.apache.org/docs/3.1.2/sql-programming-guide.html)
- Spark为机器学习提供了[MLlib](https://spark.apache.org/docs/3.1.2/ml-guide.html)
- Spark为图计算提供了[GraphX](https://spark.apache.org/docs/3.1.2/graphx-programming-guide.html)
- Spark为增量计算和流处理提供了[Structed Stream](https://spark.apache.org/docs/3.1.2/structured-streaming-programming-guide.html)

<Image src={sparkStack}/>

## 安装

### JRE

Spark是用Scala编写的，需要安装Java。版本要求8或11。

[JRE-8 下载地址][jre-download]

**注意**，你还需要正确配置`JAVA_HOME`环境变量

验证安装：

```bash
$ java -version
java version "1.8.0_271"
Java(TM) SE Runtime Environment (build 1.8.0_271-b09)
Java HotSpot(TM) Client VM (build 25.271-b09, mixed mode, sharing)

$ echo $JAVA_HOME
C:\Users\dxu\coding\jdk\jdk-8u162-windows-x64
```

### Python

我们的教学示例使用Python，需要安装Python。版本要求3.6+。

[Python 下载地址][python-download]

验证安装：

```bash
$ python --version
Python 3.6.12
```

Python安装完成后我们还要安装`pyspark`包

```bash
pip install pyspark
```

### Spark

[Spark 下载地址](http://spark.apache.org/downloads.html)

<Image src={sparkDownload}/>


现在Spark已经成功安装，你可以开始学习Spark了！

[jre-download]: https://www.oracle.com/java/technologies/javase-jre8-downloads.html
[python-download]: https://www.python.org/downloads/
[spark-download]: http://spark.apache.org/downloads.html