export const meta = {
  id: 'session',
  name: 'SparkSession',
}

`SparkSession`是Spark程序的入口。正如在WordCount一例中，我们要做的第一件事就是创建一个`SparkSession`。

## 创建

典型的创建过程如下：

```python
from pyspark.sql import SparkSession

spark = SparkSession \
    .builder \
    .master('local') \
    .appName("My Spark App") \
    .config("spark.some.config.option", "some-value") \
    .getOrCreate()
```
## 参数

### master

master选项指定了`SparkSession`连接的Spark实例，常见的master有以下几种

- `local`，创建本地Spark实例，其使用一个工作线程
- `local[n]`，创建本地Spark实例，其使用n个工作线程
- `local[*]`，创建本地Spark实例，其使用工作线程数量等同于机器core的数量
- `spark://HOST:PORT`，连接到一个Spark Standalone集群
- `k8s://HOST:PORT`，连接到K8S集群

更多master格式参见[官方文档](https://spark.apache.org/docs/3.0.0/submitting-applications.html#master-urls)

### appName

appName指定了应用的名字，这个名字会显示在Spark UI上。

这在本地模式下没什么用处，但是在集群上有多个Spark应用时，appName可以帮助快速辨别

### config

Spark应用的配置项，主要有

- 应用属性，例如使用多少个executor，每个executor多少cpu，内存
- 执行行为，

更多config选项参见[官方文档](https://spark.apache.org/docs/3.0.0/configuration.html#application-properties)